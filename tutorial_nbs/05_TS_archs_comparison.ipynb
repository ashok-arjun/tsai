{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/timeseriesAI/tsai/blob/master/tutorial_nbs/05_TS_archs_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "created by Ignacio Oguiza - email: timeseriesAI@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries ðŸ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************\n",
    "# stable = True # Set to True for latest pip version or False for main branch in GitHub\n",
    "# !pip install {\"tsai -U\" if stable else \"git+https://github.com/timeseriesAI/tsai.git\"} >> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os              : Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17\n",
      "python          : 3.8.13\n",
      "tsai            : 0.3.2\n",
      "fastai          : 2.7.7\n",
      "fastcore        : 1.5.11\n",
      "torch           : 1.11.0\n",
      "device          : cpu\n",
      "cpu cores       : 16\n",
      "threads per cpu : 1\n",
      "RAM             : 251.62 GB\n",
      "GPU memory      : N/A\n"
     ]
    }
   ],
   "source": [
    "from tsai.all import *\n",
    "# from tsai.custom import total_params\n",
    "my_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments ðŸ§ª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've run a small test to show how you can build any model in the `tsai` library using the `create_model` functions.\n",
    "\n",
    "The esiest way to do it is pass the architecture you want to use, a `TSDataLoaders` and any `kwargs` you'd like to use. The `create_model` function will pick up the necessary data from the `TSDataLoaders` object.\n",
    "\n",
    "I've used 2 multivariate time series datasets. As you can see, it's difficult to predict which architecture will work best for which dataset.\n",
    "\n",
    "Please, bear in mind that this is a very simple test without any hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>total params</th>\n",
       "      <th>train loss</th>\n",
       "      <th>valid loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ResCNN</td>\n",
       "      <td>{}</td>\n",
       "      <td>268551</td>\n",
       "      <td>0.040261</td>\n",
       "      <td>0.106178</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FCN</td>\n",
       "      <td>{}</td>\n",
       "      <td>285446</td>\n",
       "      <td>0.073328</td>\n",
       "      <td>0.115541</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ResNet</td>\n",
       "      <td>{}</td>\n",
       "      <td>490758</td>\n",
       "      <td>0.028025</td>\n",
       "      <td>0.206430</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xresnet1d34</td>\n",
       "      <td>{}</td>\n",
       "      <td>7232518</td>\n",
       "      <td>0.023036</td>\n",
       "      <td>0.296338</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>{'n_layers': 1, 'bidirectional': False}</td>\n",
       "      <td>51006</td>\n",
       "      <td>0.384695</td>\n",
       "      <td>0.345031</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>{'n_layers': 2, 'bidirectional': False}</td>\n",
       "      <td>131806</td>\n",
       "      <td>0.330229</td>\n",
       "      <td>0.384896</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>{'n_layers': 1, 'bidirectional': True}</td>\n",
       "      <td>102006</td>\n",
       "      <td>0.441388</td>\n",
       "      <td>0.398297</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>{'n_layers': 3, 'bidirectional': False}</td>\n",
       "      <td>212606</td>\n",
       "      <td>0.964975</td>\n",
       "      <td>0.931788</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          arch                              hyperparams  total params  \\\n",
       "0       ResCNN                                       {}        268551   \n",
       "1          FCN                                       {}        285446   \n",
       "2       ResNet                                       {}        490758   \n",
       "3  xresnet1d34                                       {}       7232518   \n",
       "4         LSTM  {'n_layers': 1, 'bidirectional': False}         51006   \n",
       "5         LSTM  {'n_layers': 2, 'bidirectional': False}        131806   \n",
       "6         LSTM   {'n_layers': 1, 'bidirectional': True}        102006   \n",
       "7         LSTM  {'n_layers': 3, 'bidirectional': False}        212606   \n",
       "\n",
       "   train loss  valid loss  accuracy  time  \n",
       "0    0.040261    0.106178  0.983333    19  \n",
       "1    0.073328    0.115541  0.977778    18  \n",
       "2    0.028025    0.206430  0.933333    32  \n",
       "3    0.023036    0.296338  0.916667    90  \n",
       "4    0.384695    0.345031  0.838889    28  \n",
       "5    0.330229    0.384896  0.827778    58  \n",
       "6    0.441388    0.398297  0.816667    48  \n",
       "7    0.964975    0.931788  0.500000    85  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='87' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      87.00% [87/100 01:39&lt;00:14]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.795510</td>\n",
       "      <td>1.792027</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.792918</td>\n",
       "      <td>1.791841</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.791832</td>\n",
       "      <td>1.791627</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.791649</td>\n",
       "      <td>1.791357</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.791266</td>\n",
       "      <td>1.791030</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.791335</td>\n",
       "      <td>1.790592</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.791016</td>\n",
       "      <td>1.790041</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.791114</td>\n",
       "      <td>1.789367</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.790820</td>\n",
       "      <td>1.788552</td>\n",
       "      <td>0.172222</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.790516</td>\n",
       "      <td>1.787456</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.790297</td>\n",
       "      <td>1.786078</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.789762</td>\n",
       "      <td>1.784269</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.789126</td>\n",
       "      <td>1.781818</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.788163</td>\n",
       "      <td>1.778299</td>\n",
       "      <td>0.272222</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.787213</td>\n",
       "      <td>1.772224</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.785583</td>\n",
       "      <td>1.761545</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.783189</td>\n",
       "      <td>1.741318</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.778150</td>\n",
       "      <td>1.702514</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.772027</td>\n",
       "      <td>1.624801</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.763046</td>\n",
       "      <td>1.513582</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.744515</td>\n",
       "      <td>1.471784</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.723308</td>\n",
       "      <td>1.381487</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.698520</td>\n",
       "      <td>1.326360</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.675899</td>\n",
       "      <td>1.205368</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.643213</td>\n",
       "      <td>1.135548</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.607267</td>\n",
       "      <td>1.014347</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.570228</td>\n",
       "      <td>0.981207</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.537943</td>\n",
       "      <td>0.912768</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.497367</td>\n",
       "      <td>0.827971</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.458803</td>\n",
       "      <td>0.779817</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.417981</td>\n",
       "      <td>0.731850</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.376329</td>\n",
       "      <td>0.695071</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.335225</td>\n",
       "      <td>0.702936</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.296132</td>\n",
       "      <td>0.635788</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.258417</td>\n",
       "      <td>0.715138</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.224798</td>\n",
       "      <td>0.629438</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.188006</td>\n",
       "      <td>0.569127</td>\n",
       "      <td>0.738889</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.150019</td>\n",
       "      <td>0.565045</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.115234</td>\n",
       "      <td>0.561727</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.081100</td>\n",
       "      <td>0.594642</td>\n",
       "      <td>0.738889</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.048654</td>\n",
       "      <td>0.493849</td>\n",
       "      <td>0.761111</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.016956</td>\n",
       "      <td>0.417591</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.987028</td>\n",
       "      <td>0.387472</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.956995</td>\n",
       "      <td>0.376359</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.927305</td>\n",
       "      <td>0.375932</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.898390</td>\n",
       "      <td>0.461450</td>\n",
       "      <td>0.794444</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.874418</td>\n",
       "      <td>0.370365</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.849340</td>\n",
       "      <td>0.417837</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.826635</td>\n",
       "      <td>0.368151</td>\n",
       "      <td>0.794444</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.804661</td>\n",
       "      <td>0.393137</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.782698</td>\n",
       "      <td>0.380492</td>\n",
       "      <td>0.794444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.758950</td>\n",
       "      <td>0.378052</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.736762</td>\n",
       "      <td>0.403621</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.718037</td>\n",
       "      <td>0.391191</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.699816</td>\n",
       "      <td>0.387610</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.681896</td>\n",
       "      <td>0.373551</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.662221</td>\n",
       "      <td>0.387691</td>\n",
       "      <td>0.794444</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.645676</td>\n",
       "      <td>0.383781</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.628302</td>\n",
       "      <td>0.389916</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.612013</td>\n",
       "      <td>0.391014</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.596839</td>\n",
       "      <td>0.389813</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.581722</td>\n",
       "      <td>0.391192</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.568462</td>\n",
       "      <td>0.391449</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.555100</td>\n",
       "      <td>0.390912</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.541862</td>\n",
       "      <td>0.390495</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.529516</td>\n",
       "      <td>0.391338</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.517178</td>\n",
       "      <td>0.393578</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.504400</td>\n",
       "      <td>0.396926</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.492235</td>\n",
       "      <td>0.400601</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.481505</td>\n",
       "      <td>0.400463</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.471589</td>\n",
       "      <td>0.399502</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.462022</td>\n",
       "      <td>0.398095</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.451387</td>\n",
       "      <td>0.396983</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.441893</td>\n",
       "      <td>0.396021</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.432998</td>\n",
       "      <td>0.394551</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.425506</td>\n",
       "      <td>0.393854</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.416782</td>\n",
       "      <td>0.393258</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.408206</td>\n",
       "      <td>0.392635</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.401380</td>\n",
       "      <td>0.392306</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.394584</td>\n",
       "      <td>0.392513</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.388625</td>\n",
       "      <td>0.393060</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.381821</td>\n",
       "      <td>0.393744</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.375802</td>\n",
       "      <td>0.394888</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.370838</td>\n",
       "      <td>0.396450</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.366167</td>\n",
       "      <td>0.397572</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.361272</td>\n",
       "      <td>0.399010</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.355937</td>\n",
       "      <td>0.400995</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/2 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/dccstor/w_reps/tsai/tutorial_nbs/05_TS_archs_comparison.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2249424d2d434343227d/dccstor/w_reps/tsai/tutorial_nbs/05_TS_archs_comparison.ipynb#ch0000007vscode-remote?line=17'>18</a>\u001b[0m learn \u001b[39m=\u001b[39m Learner(dls, model,  metrics\u001b[39m=\u001b[39maccuracy)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2249424d2d434343227d/dccstor/w_reps/tsai/tutorial_nbs/05_TS_archs_comparison.ipynb#ch0000007vscode-remote?line=18'>19</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2249424d2d434343227d/dccstor/w_reps/tsai/tutorial_nbs/05_TS_archs_comparison.ipynb#ch0000007vscode-remote?line=19'>20</a>\u001b[0m learn\u001b[39m.\u001b[39;49mfit_one_cycle(\u001b[39m100\u001b[39;49m, \u001b[39m1e-3\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2249424d2d434343227d/dccstor/w_reps/tsai/tutorial_nbs/05_TS_archs_comparison.ipynb#ch0000007vscode-remote?line=20'>21</a>\u001b[0m elapsed \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2249424d2d434343227d/dccstor/w_reps/tsai/tutorial_nbs/05_TS_archs_comparison.ipynb#ch0000007vscode-remote?line=21'>22</a>\u001b[0m vals \u001b[39m=\u001b[39m learn\u001b[39m.\u001b[39mrecorder\u001b[39m.\u001b[39mvalues[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/mvts/lib/python3.8/site-packages/fastai/callback/schedule.py:122\u001b[0m, in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    119\u001b[0m lr_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([h[\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mhypers])\n\u001b[1;32m    120\u001b[0m scheds \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m: combined_cos(pct_start, lr_max\u001b[39m/\u001b[39mdiv, lr_max, lr_max\u001b[39m/\u001b[39mdiv_final),\n\u001b[1;32m    121\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mmom\u001b[39m\u001b[39m'\u001b[39m: combined_cos(pct_start, \u001b[39m*\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmoms \u001b[39mif\u001b[39;00m moms \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m moms))}\n\u001b[0;32m--> 122\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(n_epoch, cbs\u001b[39m=\u001b[39;49mParamScheduler(scheds)\u001b[39m+\u001b[39;49mL(cbs), reset_opt\u001b[39m=\u001b[39;49mreset_opt, wd\u001b[39m=\u001b[39;49mwd, start_epoch\u001b[39m=\u001b[39;49mstart_epoch)\n",
      "File \u001b[0;32m~/miniconda3/envs/mvts/lib/python3.8/site-packages/fastai/learner.py:242\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mset_hypers(lr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr \u001b[39mif\u001b[39;00m lr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m lr)\n\u001b[1;32m    241\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_epoch \u001b[39m=\u001b[39m n_epoch\n\u001b[0;32m--> 242\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_fit, \u001b[39m'\u001b[39;49m\u001b[39mfit\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelFitException, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_end_cleanup)\n",
      "File \u001b[0;32m~/miniconda3/envs/mvts/lib/python3.8/site-packages/fastai/learner.py:179\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[1;32m    180\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    181\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/mvts/lib/python3.8/site-packages/fastai/learner.py:231\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_epoch):\n\u001b[1;32m    230\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch\u001b[39m=\u001b[39mepoch\n\u001b[0;32m--> 231\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_epoch, \u001b[39m'\u001b[39;49m\u001b[39mepoch\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelEpochException)\n",
      "File \u001b[0;32m~/miniconda3/envs/mvts/lib/python3.8/site-packages/fastai/learner.py:179\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[1;32m    180\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    181\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/mvts/lib/python3.8/site-packages/fastai/learner.py:225\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_epoch\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 225\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_epoch_train()\n\u001b[1;32m    226\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[0;32m~/miniconda3/envs/mvts/lib/python3.8/site-packages/fastai/learner.py:217\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_epoch_train\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls\u001b[39m.\u001b[39mtrain\n\u001b[0;32m--> 217\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mall_batches, \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelTrainException)\n",
      "File \u001b[0;32m~/miniconda3/envs/mvts/lib/python3.8/site-packages/fastai/learner.py:179\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[1;32m    180\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    181\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/mvts/lib/python3.8/site-packages/fastai/learner.py:185\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mall_batches\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    184\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl)\n\u001b[0;32m--> 185\u001b[0m     \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl): \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mone_batch(\u001b[39m*\u001b[39;49mo)\n",
      "File \u001b[0;32m/dccstor/w_reps/tsai/tutorial_nbs/tsai/learner.py:38\u001b[0m, in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m     36\u001b[0m b_on_device \u001b[39m=\u001b[39m to_device(b, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls\u001b[39m.\u001b[39mdevice) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls\u001b[39m.\u001b[39mdevice \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m b\n\u001b[1;32m     37\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split(b_on_device)\n\u001b[0;32m---> 38\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_one_batch, \u001b[39m'\u001b[39;49m\u001b[39mbatch\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelBatchException)\n",
      "File \u001b[0;32m~/miniconda3/envs/mvts/lib/python3.8/site-packages/fastai/learner.py:179\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[1;32m    180\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    181\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/mvts/lib/python3.8/site-packages/fastai/learner.py:198\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39mself\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mafter_loss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    197\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39myb): \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backward, \u001b[39m'\u001b[39;49m\u001b[39mbackward\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelBackwardException)\n\u001b[1;32m    199\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_with_events(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step, \u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m, CancelStepException)\n\u001b[1;32m    200\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/mvts/lib/python3.8/site-packages/fastai/learner.py:179\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[1;32m    180\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    181\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/mvts/lib/python3.8/site-packages/fastai/learner.py:187\u001b[0m, in \u001b[0;36mLearner._backward\u001b[0;34m(self)\u001b[0m\n\u001b[0;32m--> 187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_backward\u001b[39m(\u001b[39mself\u001b[39m): \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_grad\u001b[39m.\u001b[39;49mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/mvts/lib/python3.8/site-packages/torch/_tensor.py:355\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \n\u001b[1;32m    310\u001b[0m \u001b[39mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39;49mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39;49m,),\n\u001b[1;32m    358\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    359\u001b[0m         gradient\u001b[39m=\u001b[39;49mgradient,\n\u001b[1;32m    360\u001b[0m         retain_graph\u001b[39m=\u001b[39;49mretain_graph,\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39;49mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39;49minputs)\n\u001b[1;32m    363\u001b[0m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mbackward(\u001b[39mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39minputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/mvts/lib/python3.8/site-packages/torch/overrides.py:1394\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1388\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mDefining your `__torch_function__ as a plain method is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1389\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39mwill be an error in PyTorch 1.11, please define it as a classmethod.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1390\u001b[0m                   \u001b[39mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m   1392\u001b[0m \u001b[39m# Use `public_api` instead of `implementation` so __torch_function__\u001b[39;00m\n\u001b[1;32m   1393\u001b[0m \u001b[39m# implementations can do equality/identity comparisons.\u001b[39;00m\n\u001b[0;32m-> 1394\u001b[0m result \u001b[39m=\u001b[39m torch_func_method(public_api, types, args, kwargs)\n\u001b[1;32m   1396\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   1397\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/mvts/lib/python3.8/site-packages/fastai/torch_core.py:379\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mdebug \u001b[39mand\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39m__str__\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m__repr__\u001b[39m\u001b[39m'\u001b[39m): \u001b[39mprint\u001b[39m(func, types, args, kwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mif\u001b[39;00m _torch_handled(args, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_opt, func): types \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39mTensor,)\n\u001b[0;32m--> 379\u001b[0m res \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m__torch_function__(func, types, args, ifnone(kwargs, {}))\n\u001b[1;32m    380\u001b[0m dict_objs \u001b[39m=\u001b[39m _find_args(args) \u001b[39mif\u001b[39;00m args \u001b[39melse\u001b[39;00m _find_args(\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mvalues()))\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mtype\u001b[39m(res),TensorBase) \u001b[39mand\u001b[39;00m dict_objs: res\u001b[39m.\u001b[39mset_meta(dict_objs[\u001b[39m0\u001b[39m],as_copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mvts/lib/python3.8/site-packages/torch/_tensor.py:1142\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m   1141\u001b[0m \u001b[39mwith\u001b[39;00m _C\u001b[39m.\u001b[39mDisableTorchFunction():\n\u001b[0;32m-> 1142\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mif\u001b[39;00m func \u001b[39min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1144\u001b[0m         \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/miniconda3/envs/mvts/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/mvts/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dsid = 'NATOPS' \n",
    "bs = 64\n",
    "X, y, splits = get_UCR_data(dsid, return_split=False)\n",
    "print(X.shape)\n",
    "tfms  = [None, [Categorize()]]\n",
    "dsets = TSDatasets(X, y, tfms=tfms, splits=splits)\n",
    "dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[bs, bs*2])\n",
    "\n",
    "archs = [(FCN, {}), (ResNet, {}), (xresnet1d34, {}), (ResCNN, {}), \n",
    "         (LSTM, {'n_layers':1, 'bidirectional': False}), (LSTM, {'n_layers':2, 'bidirectional': False}), (LSTM, {'n_layers':3, 'bidirectional': False}), \n",
    "         (LSTM, {'n_layers':1, 'bidirectional': True}), (LSTM, {'n_layers':2, 'bidirectional': True}), (LSTM, {'n_layers':3, 'bidirectional': True}),\n",
    "         (LSTM_FCN, {}), (LSTM_FCN, {'shuffle': False}), (InceptionTime, {}), (XceptionTime, {}), (OmniScaleCNN, {}), (mWDN, {'levels': 4})]\n",
    "\n",
    "results = pd.DataFrame(columns=['arch', 'hyperparams', 'total params', 'train loss', 'valid loss', 'accuracy', 'time'])\n",
    "for i, (arch, k) in enumerate(archs):\n",
    "    model = create_model(arch, dls=dls, **k)\n",
    "    print(model.__class__.__name__)\n",
    "    learn = Learner(dls, model,  metrics=accuracy)\n",
    "    start = time.time()\n",
    "    learn.fit_one_cycle(100, 1e-3)\n",
    "    elapsed = time.time() - start\n",
    "    vals = learn.recorder.values[-1]\n",
    "    results.loc[i] = [arch.__name__, k, total_params(model), vals[0], vals[1], vals[2], int(elapsed)]\n",
    "    results.sort_values(by='accuracy', ascending=False, ignore_index=True, inplace=True)\n",
    "    clear_output()\n",
    "    display(results)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tsai.custom.total_params(model)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tsai.custom import total_params\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>total params</th>\n",
       "      <th>train loss</th>\n",
       "      <th>valid loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XceptionTime</td>\n",
       "      <td>{}</td>\n",
       "      <td>401580</td>\n",
       "      <td>0.074442</td>\n",
       "      <td>1.488087</td>\n",
       "      <td>0.678832</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>{'n_layers': 3, 'bidirectional': True}</td>\n",
       "      <td>572414</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>2.650948</td>\n",
       "      <td>0.669505</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ResCNN</td>\n",
       "      <td>{}</td>\n",
       "      <td>260367</td>\n",
       "      <td>0.250915</td>\n",
       "      <td>1.266159</td>\n",
       "      <td>0.667883</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM_FCN</td>\n",
       "      <td>{'shuffle': False}</td>\n",
       "      <td>314950</td>\n",
       "      <td>0.440930</td>\n",
       "      <td>1.236977</td>\n",
       "      <td>0.657340</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ResNet</td>\n",
       "      <td>{}</td>\n",
       "      <td>482574</td>\n",
       "      <td>0.030630</td>\n",
       "      <td>2.362593</td>\n",
       "      <td>0.650446</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>{'n_layers': 2, 'bidirectional': False}</td>\n",
       "      <td>125414</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>2.354824</td>\n",
       "      <td>0.650041</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>{'n_layers': 2, 'bidirectional': True}</td>\n",
       "      <td>330814</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>2.637241</td>\n",
       "      <td>0.644769</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>{'n_layers': 3, 'bidirectional': False}</td>\n",
       "      <td>206214</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>2.461025</td>\n",
       "      <td>0.633820</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>{'n_layers': 1, 'bidirectional': False}</td>\n",
       "      <td>44614</td>\n",
       "      <td>0.054411</td>\n",
       "      <td>1.819723</td>\n",
       "      <td>0.616788</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>{'n_layers': 1, 'bidirectional': True}</td>\n",
       "      <td>89214</td>\n",
       "      <td>0.053924</td>\n",
       "      <td>1.760913</td>\n",
       "      <td>0.596918</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LSTM_FCN</td>\n",
       "      <td>{}</td>\n",
       "      <td>326950</td>\n",
       "      <td>0.480608</td>\n",
       "      <td>1.561972</td>\n",
       "      <td>0.575020</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OmniScaleCNN</td>\n",
       "      <td>{}</td>\n",
       "      <td>1432716</td>\n",
       "      <td>0.678315</td>\n",
       "      <td>2.100926</td>\n",
       "      <td>0.564477</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FCN</td>\n",
       "      <td>{}</td>\n",
       "      <td>270350</td>\n",
       "      <td>0.834407</td>\n",
       "      <td>1.705541</td>\n",
       "      <td>0.564071</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mWDN</td>\n",
       "      <td>{'levels': 4}</td>\n",
       "      <td>461182</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>2.706592</td>\n",
       "      <td>0.521492</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>{}</td>\n",
       "      <td>457614</td>\n",
       "      <td>0.253975</td>\n",
       "      <td>2.961505</td>\n",
       "      <td>0.448905</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xresnet1d34</td>\n",
       "      <td>{}</td>\n",
       "      <td>7234894</td>\n",
       "      <td>0.068992</td>\n",
       "      <td>4.470646</td>\n",
       "      <td>0.414436</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             arch                              hyperparams  ...  accuracy  time\n",
       "0    XceptionTime                                       {}  ...  0.678832   100\n",
       "1            LSTM   {'n_layers': 3, 'bidirectional': True}  ...  0.669505    98\n",
       "2          ResCNN                                       {}  ...  0.667883    60\n",
       "3        LSTM_FCN                       {'shuffle': False}  ...  0.657340    59\n",
       "4          ResNet                                       {}  ...  0.650446    78\n",
       "5            LSTM  {'n_layers': 2, 'bidirectional': False}  ...  0.650041    56\n",
       "6            LSTM   {'n_layers': 2, 'bidirectional': True}  ...  0.644769    76\n",
       "7            LSTM  {'n_layers': 3, 'bidirectional': False}  ...  0.633820    66\n",
       "8            LSTM  {'n_layers': 1, 'bidirectional': False}  ...  0.616788    45\n",
       "9            LSTM   {'n_layers': 1, 'bidirectional': True}  ...  0.596918    56\n",
       "10       LSTM_FCN                                       {}  ...  0.575020    53\n",
       "11   OmniScaleCNN                                       {}  ...  0.564477    93\n",
       "12            FCN                                       {}  ...  0.564071    46\n",
       "13           mWDN                            {'levels': 4}  ...  0.521492   120\n",
       "14  InceptionTime                                       {}  ...  0.448905   107\n",
       "15    xresnet1d34                                       {}  ...  0.414436   181\n",
       "\n",
       "[16 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dsid = 'LSST' \n",
    "bs = 64\n",
    "X, y, splits = get_UCR_data(dsid, return_split=False)\n",
    "print(X.shape)\n",
    "tfms  = [None, [Categorize()]]\n",
    "dsets = TSDatasets(X, y, tfms=tfms, splits=splits)\n",
    "dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[bs, bs*2])\n",
    "\n",
    "archs = [(FCN, {}), (ResNet, {}), (xresnet1d34, {}), (ResCNN, {}), \n",
    "         (LSTM, {'n_layers':1, 'bidirectional': False}), (LSTM, {'n_layers':2, 'bidirectional': False}), (LSTM, {'n_layers':3, 'bidirectional': False}), \n",
    "         (LSTM, {'n_layers':1, 'bidirectional': True}), (LSTM, {'n_layers':2, 'bidirectional': True}), (LSTM, {'n_layers':3, 'bidirectional': True}),\n",
    "         (LSTM_FCN, {}), (LSTM_FCN, {'shuffle': False}), (InceptionTime, {}), (XceptionTime, {}), (OmniScaleCNN, {}), (mWDN, {'levels': 4})]\n",
    "\n",
    "results = pd.DataFrame(columns=['arch', 'hyperparams', 'total params', 'train loss', 'valid loss', 'accuracy', 'time'])\n",
    "for i, (arch, k) in enumerate(archs):\n",
    "    model = create_model(arch, dls=dls, **k)\n",
    "    print(model.__class__.__name__)\n",
    "    learn = Learner(dls, model,  metrics=accuracy)\n",
    "    start = time.time()\n",
    "    learn.fit_one_cycle(100, 1e-3)\n",
    "    elapsed = time.time() - start\n",
    "    vals = learn.recorder.values[-1]\n",
    "    results.loc[i] = [arch.__name__, k, total_params(model)[0], vals[0], vals[1], vals[2], int(elapsed)]\n",
    "    results.sort_values(by='accuracy', ascending=False, ignore_index=True, inplace=True)\n",
    "    clear_output()\n",
    "    display(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mvts')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6739bd610766028c4f6a4b31bc1140e91f2ddb102aa8535398c0cc486d6dd3dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
